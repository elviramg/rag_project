{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain RAG Project with Pride and Prejudice book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ENV variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('../Data/pride_and_prejudice.txt', encoding='utf-8')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore.save_local(\"../faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = FAISS.load_local(\"../persistence/langchain/faiss_index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(search_type=\"similarity\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Eres un consejero amoroso con la sabiduría y el estilo de Jane Austen, la autora de \"Orgullo y Prejuicio\".\n",
    "Basándote exclusivamente en el contenido del libro y la época en que fue escrito, proporciona consejos sobre relaciones y amor.\n",
    "\n",
    "Contexto del libro: {context}\n",
    "\n",
    "Pregunta del usuario: {question}\n",
    "\n",
    "Por favor, sigue estas instrucciones al responder:\n",
    "1. Proporciona un consejo amoroso que refleje los valores y la sensibilidad de la época de Jane Austen, pero adaptado a la situación moderna del usuario.\n",
    "2. El consejo debe estar estrictamente basado en la información y los temas presentes en \"Orgullo y Prejuicio\".\n",
    "3. Incluye una cita textual relevante del libro que respalde tu consejo.\n",
    "4. Sé educado, ingenioso y un poco formal en tu respuesta, como lo sería un personaje de Austen.\n",
    "5. Si no hay información relevante en el contexto proporcionado para responder la pregunta, admítelo cortésmente.\n",
    "\n",
    "Consejo:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    condense_question_prompt=prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "\n",
    "def get_love_advice(question):\n",
    "    global chat_history\n",
    "    inputs = {\"question\": question, \"chat_history\": chat_history}\n",
    "    result = rag_chain(inputs)\n",
    "    answer = result['answer']\n",
    "    chat_history.append((question, answer))\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/3qs0qblx57384mws5h46m82m0000gn/T/ipykernel_58855/2664503527.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = rag_chain(inputs)\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "“In vain have I struggled. It will not do. My feelings will not be\n",
      "repressed. You must allow me to tell you how ardently I admire and love\n",
      "you.”\n",
      "\n",
      "being in love with each other many weeks.”\n",
      "\n",
      "“Very, very much. Nothing could give either Bingley or myself more\n",
      "delight. But we considered it, we talked of it as impossible. And do you\n",
      "really love him quite well enough? Oh, Lizzy! do anything rather than\n",
      "marry without affection. Are you quite sure that you feel what you ought\n",
      "to do?”\n",
      "\n",
      "“Oh, yes! You will only think I feel _more_ than I ought to do when I\n",
      "tell you all.”\n",
      "\n",
      "“What do you mean?”\n",
      "\n",
      "“Why, I must confess that I love him better than I do Bingley. I am\n",
      "afraid you will be angry.”\n",
      "\n",
      "should be very sorry to be the means of making any of you unhappy; but\n",
      "since we see, every day, that where there is affection young people are\n",
      "seldom withheld, by immediate want of fortune, from entering into\n",
      "engagements with each other, how can I promise to be wiser than so many\n",
      "of my fellow-creatures, if I am tempted, or how am I even to know that\n",
      "it would be wiser to resist? All that I can promise you, therefore, is\n",
      "not to be in a hurry. I will not be in a hurry to believe myself his\n",
      "Human: Estoy perdidamente enamorado de mi mejor amigo, pero no se si es el amor verdadero.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Basándome en el fragmento proporcionado, parece que el personaje principal también tenía dudas sobre sus sentimientos y si era amor verdadero. Puede ser útil reflexionar sobre tus sentimientos y considerar si realmente sientes una conexión profunda y genuina con tu amigo antes de tomar decisiones importantes. ¡Buena suerte!\n"
     ]
    }
   ],
   "source": [
    "get_love_advice(\"Estoy perdidamente enamorado de mi mejor amigo, pero no se si es el amor verdadero.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
