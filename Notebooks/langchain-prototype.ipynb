{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain RAG Project with Pride and Prejudice book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ENV variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.0\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elviramagallanes/.pyenv/versions/langchain_rag/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('Data/pride_and_prejudice.txt', encoding='utf-8')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/3qs0qblx57384mws5h46m82m0000gn/T/ipykernel_21585/1876906078.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "/Users/elviramagallanes/.pyenv/versions/langchain_rag/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/elviramagallanes/.pyenv/versions/langchain_rag/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our vector storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vectorstore = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "new_vector_store = FAISS.load_local(\n",
    "    \"faiss_index\", embeddings, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()\n",
    "retrieval_chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM (CHAT BOT IMPLEMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/3qs0qblx57384mws5h46m82m0000gn/T/ipykernel_21585/2627565311.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"
     ]
    }
   ],
   "source": [
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = (\n",
    "'''Below you can find pride and prejudice book. This book it's a romantic novel, that every romantic person should know.\n",
    "\n",
    "writings:\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "\n",
    "I will describe a scenario I’m going through in my life. Your task is the following:\n",
    "\n",
    "1. Clearly understand the scenario I’m describing, pay attention to the context.\n",
    "2. Extract a quote from the book that gives guidance on how a romantic person should handle the scenario I’m describing. You should extract the quote exactly as it is, without modifying it.\n",
    "\n",
    "scenario: {query_str}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"context_str\", \"query_str\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"I'm really in love with my boyfriend, but I'm not sure if he feels the same way. What should I do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'Data/pride_and_prejudice.txt'}, page_content='of being in love with you, he is very much in love with her friend.”'), Document(metadata={'source': 'Data/pride_and_prejudice.txt'}, page_content='“I think you are in very great danger of making him as much in love with\\nyou as ever.”'), Document(metadata={'source': 'Data/pride_and_prejudice.txt'}, page_content='other feelings which will probably soon drive away his regard for me.'), Document(metadata={'source': 'Data/pride_and_prejudice.txt'}, page_content='his falling in love at all is not extremely probable. Here again I')]\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(user_query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of being in love with you, he is very much in love with her friend.”\n",
      "\n",
      "“I think you are in very great danger of making him as much in love with\n",
      "you as ever.”\n",
      "\n",
      "other feelings which will probably soon drive away his regard for me.\n",
      "\n",
      "his falling in love at all is not extremely probable. Here again I\n"
     ]
    }
   ],
   "source": [
    "context = \"\\n\\n\".join([getattr(doc, 'page_content', '') for doc in docs])\n",
    "print(context)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below you can find pride and prejudice book. This book it's a romantic novel, that every romantic person should know.\n",
      "\n",
      "writings:\n",
      "---------------------\n",
      "of being in love with you, he is very much in love with her friend.”\n",
      "\n",
      "“I think you are in very great danger of making him as much in love with\n",
      "you as ever.”\n",
      "\n",
      "other feelings which will probably soon drive away his regard for me.\n",
      "\n",
      "his falling in love at all is not extremely probable. Here again I\n",
      "---------------------\n",
      "\n",
      "I will describe a scenario I’m going through in my life. Your task is the following:\n",
      "\n",
      "1. Clearly understand the scenario I’m describing, pay attention to the context.\n",
      "2. Extract a quote from the book that gives guidance on how a romantic person should handle the scenario I’m describing. You should extract the quote exactly as it is, without modifying it.\n",
      "\n",
      "scenario: I'm really in love with my boyfriend, but I'm not sure if he feels the same way. What should I do?\n"
     ]
    }
   ],
   "source": [
    "prompt_input = prompt.format(context_str=context, query_str=user_query)\n",
    "print(prompt_input)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
